# -*- coding: utf-8 -*-
"""Breast_Cancer_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ofCfZbLWPkYVpott11DP0AieGfnHwSyB

Accurately diagnosing breast tumors as either cancerous (malignant) or non-cancerous (benign) is crucial for a patient's life expectancy and quality of life. Misdiagnosis can have severe consequences on a patient's medical condition. Unfortunately, even with human intervention and medical expertise, misdiagnoses of breast tumors occur frequently. This highlights the need for a machine learning-based system that can diagnose breast tumors with a high degree of accuracy, potentially surpassing the performance of medical experts. By utilizing a dataset of breast tumors, we can develop a system that learns to accurately diagnose breast tumors from the data provided.To address this problem, we will train a Naive Bayes Classifier from scratch. We will also evaluate the classifier's performance.
"""

# ðŸ“Œ Import Required Libraries
import pandas as pd
import numpy as np
import seaborn as sns
import scipy.stats as s
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report
import joblib

# ðŸ“Œ Load & Clean Data
data = pd.read_csv("data.csv")

# Remove unnecessary columns
if "Unnamed: 32" in data.columns:
    data.drop(columns=["Unnamed: 32"], inplace=True)
if "id" in data.columns:
    data.drop(columns=["id"], inplace=True)

# Convert Diagnosis Labels to Numeric (B=0, M=1)
data["diagnosis"] = data["diagnosis"].map({"B": 0, "M": 1})

# ðŸ“Œ Compute Correlation Matrix
corr_matrix = data.corr()

# Select Top 8 Most Correlated Features (Excluding Diagnosis)
strong_features = corr_matrix["diagnosis"].nlargest(9).iloc[1:].index.tolist()

# Keep Only Selected Features for Training
data = data[strong_features + ["diagnosis"]]

# ðŸ“Œ Split Data into Malignant & Benign Cases
class0_data = data[data["diagnosis"] == 0]
class1_data = data[data["diagnosis"] == 1]

# Train-Test Split (75%-25%)
train_size_0 = int(0.75 * len(class0_data))
train_size_1 = int(0.75 * len(class1_data))

train_data = pd.concat([class0_data.iloc[:train_size_0], class1_data.iloc[:train_size_1]])
test_data = pd.concat([class0_data.iloc[train_size_0:], class1_data.iloc[train_size_1:]])

# ðŸ“Œ Compute Gaussian Parameters (Mean & Covariance)
mu_0 = train_data[train_data["diagnosis"] == 0].iloc[:, :-1].mean().values
sigma_0 = train_data[train_data["diagnosis"] == 0].iloc[:, :-1].cov().values

mu_1 = train_data[train_data["diagnosis"] == 1].iloc[:, :-1].mean().values
sigma_1 = train_data[train_data["diagnosis"] == 1].iloc[:, :-1].cov().values

# ðŸ“Œ Save Model Parameters
joblib.dump((mu_0, sigma_0, mu_1, sigma_1, strong_features), "gaussian_parameters.pkl")
print("âœ… Gaussian Parameters Saved Successfully!")

# ðŸ“Œ Define Prediction Function
def predict_classes(data):
    """Predict class using Gaussian Naive Bayes."""
    data = data[strong_features]  # Ensure same features are used
    p_xi_on_class1 = s.multivariate_normal.pdf(data, mu_1, sigma_1)
    p_xi_on_class0 = s.multivariate_normal.pdf(data, mu_0, sigma_0)
    return (p_xi_on_class1 > p_xi_on_class0).astype(int)

# ðŸ“Œ Evaluate Model
y_true = test_data["diagnosis"]
y_pred = predict_classes(test_data.iloc[:, :-1])

print("\nðŸ”¹ Confusion Matrix:\n", confusion_matrix(y_true, y_pred))
print("\nðŸ”¹ Classification Report:\n", classification_report(y_true, y_pred))

# ðŸ“Œ Visualize Feature Correlations
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)
plt.title("Feature Correlation Matrix")
plt.show()